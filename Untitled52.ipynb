{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb97e9c-05af-4af6-abf4-b210ab6e10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Min-Max scaling is a data scaling technique that transforms the values of each feature in a dataset to a range of 0 to 1. \n",
    "This is done by subtracting the minimum value of each feature from all the values of that feature, and then dividing by the \n",
    "difference between the maximum and minimum values.\n",
    "\n",
    "For example, let's say we have a dataset of house prices with a minimum value of $100,000 and a maximum value of $1,000,000.\n",
    "If we apply Min-Max scaling to this dataset, then all the house prices will be transformed to a range of 0 to 1.\n",
    "A house price of $100,000 would be scaled to 0, a house price of $1,000,000 would be scaled to 1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514df005-7f85-400b-9ec8-9b1c933035ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "The unit vector technique scales features by dividing each feature vector by its L2 norm. This preserves the direction of the feature vectors.\n",
    "Min-Max scaling transforms the values of each feature in a dataset to a range of 0 to 1. This does not preserve the direction of the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595e489-7e7a-48b6-aff5-0884bc131cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA is a statistical procedure that reduces the dimensionality of a dataset by transforming the data into a new set of uncorrelated variables called principal components.\n",
    "The principal components are ordered in decreasing order of explained variance, so the first principal component accounts for the most variance in the data, the second principal component accounts for the second most variance, and so on.\n",
    "PCA can be used to reduce the dimensionality of a dataset by retaining only the most important principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a77c1a-3507-499c-8a10-ead8c9bffc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA is a dimensionality reduction technique that can be used to extract features from a dataset.\n",
    "Feature extraction is the process of transforming raw data into a set of features that are more relevant to the problem at hand.\n",
    "PCA can be used for feature extraction by retaining only the most important principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bcdf2-69f3-4cdc-aece-f28ec420bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import the MinMaxScaler library from scikit-learn.\n",
    "Create a MinMaxScaler object.\n",
    "Fit the MinMaxScaler object to the dataset.\n",
    "This will calculate the minimum and maximum values of each feature in the dataset.\n",
    "\n",
    "Transform the dataset using the MinMaxScaler object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeebf24-1235-4969-8274-e4fc5fc548e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import the PCA library from scikit-learn.\n",
    "Create a PCA object.\n",
    "Fit the PCA object to the dataset.\n",
    "This will calculate the principal components of the dataset.\n",
    "\n",
    "Transform the dataset using the PCA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24033231-0f5c-4ccd-bfdb-0962295cd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the dataset\n",
    "data = [1, 5, 10, 15, 20]\n",
    "\n",
    "# Calculate the minimum and maximum values\n",
    "min_value = np.min(data)\n",
    "max_value = np.max(data)\n",
    "\n",
    "# Perform Min-Max scaling\n",
    "scaled_data = (data - min_value) / (max_value - min_value)\n",
    "\n",
    "# Print the scaled data\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0924a-5372-4806-b59d-cee34200a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create the dataset\n",
    "data = np.array([[170, 70, 30, 1, 120],\n",
    "                  [160, 60, 25, 0, 110],\n",
    "                  [180, 80, 40, 1, 130]])\n",
    "\n",
    "# Create the PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# Fit the PCA object to the dataset\n",
    "pca.fit(data)\n",
    "\n",
    "# Transform the dataset using the PCA object\n",
    "principal_components = pca.transform(data)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
